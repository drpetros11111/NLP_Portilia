{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drpetros11111/NLP_Portilia/blob/NLP_Spacy_Basics_1/00_POS_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCEYpJYwghMp"
      },
      "source": [
        "___\n",
        "\n",
        "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfhqiK3AghMr"
      },
      "source": [
        "# Part of Speech Basics\n",
        "The challenge of correctly identifying parts of speech is summed up nicely in the [spaCy docs](https://spacy.io/usage/linguistic-features):\n",
        "<div class=\"alert alert-info\" style=\"margin: 20px\">Processing raw text intelligently is difficult: most words are rare, and it's common for words that look completely different to mean almost the same thing. The same words in a different order can mean something completely different. Even splitting text into useful word-like units can be difficult in many languages. While it's possible to solve some problems starting from only the raw characters, it's usually better to use linguistic knowledge to add useful information. That's exactly what spaCy is designed to do: you put in raw text, and get back a **Doc** object, that comes with a variety of annotations.</div>\n",
        "In this section we'll take a closer look at coarse POS tags (noun, verb, adjective) and fine-grained tags (plural noun, past-tense verb, superlative adjective)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lT1MpU3jghMs"
      },
      "outputs": [],
      "source": [
        "# Perform standard imports\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import spacy\n",
        "\n",
        "This imports the spacy library, which provides various tools and models for working with text, such as tokenization, part-of-speech tagging, named entity recognition (NER), and more.\n",
        "\n",
        "    nlp = spacy.load('en_core_web_sm'):\n",
        "\n",
        "##spacy.load()\n",
        "\n",
        "loads a pre-trained language model into memory. In this case, it's loading the 'en_core_web_sm' model, which is a small\n",
        "\n",
        "##English language model.\n",
        "    'en_core_web_sm':\n",
        "\n",
        "en: Refers to the English language.\n",
        "\n",
        "core: Indicates this is a core model for general-purpose NLP tasks.\n",
        "\n",
        "web: Suggests it was trained on web-based text data.\n",
        "\n",
        "sm: Denotes that it’s a small model, optimized for speed and efficiency.\n",
        "\n",
        "Larger models (like md for medium and lg for large) exist, but they require more memory and are more accurate.\n",
        "\n",
        "Once the model is loaded into the nlp variable, you can process text with it by passing a string to nlp, and it will return a Doc object with the processed linguistic information. For example:\n",
        "\n",
        "    doc = nlp(\"This is a sentence.\")\n",
        "    \n",
        "Now, doc contains tokenized words, part-of-speech tags, syntactic dependencies, and possibly recognized entities from the sentence."
      ],
      "metadata": {
        "id": "3hSoEVbYhj0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VvqogennghMt"
      },
      "outputs": [],
      "source": [
        "# Create a simple Doc object\n",
        "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a simple Doc object\n",
        "\n",
        "u: This denotes that the string is a Unicode string (in Python 2.x).\n",
        "\n",
        "In Python 3.x, this u prefix is optional because all strings are Unicode by default.\n",
        "\n",
        "nlp(\"The quick brown fox jumped over the lazy dog's back.\"): This passes the string to the nlp object, which processes the text.\n",
        "\n",
        "The result, doc, is a Doc object that contains tokens and various annotations like part-of-speech (POS) tags, named entities, syntactic dependencies, etc.\n",
        "\n",
        "--------------------------------\n",
        "------------------------------\n",
        "#Note\n",
        "Unicode is a universal character encoding standard designed to support text from all writing systems around the world.\n",
        "\n",
        "It assigns a unique number (called a code point) to every character, allowing for the consistent representation of text, regardless of the platform, program, or language.\n",
        "\n",
        "------------------------\n",
        "#Key Points About Unicode:\n",
        "##Global Character Set:\n",
        "\n",
        "Unicode includes characters from most of the world's writing systems, such as Latin, Greek, Cyrillic, Arabic, Chinese, Hindi, and more.\n",
        "\n",
        "It also includes symbols, punctuation marks, emoji, and special characters like math symbols.\n",
        "Code Points:\n",
        "\n",
        "Each character is represented by a unique code point, written as U+ followed by a hexadecimal value.\n",
        "\n",
        "##For example:\n",
        "The letter \"A\" is U+0041\n",
        "\n",
        "The Greek letter \"Ω\" is U+03A9\n",
        "\n",
        "The emoji \"😊\" is U+1F60A\n",
        "\n",
        "-------------------\n",
        "##Encodings:\n",
        "\n",
        "Unicode itself is an abstract standard, but the way these code points are stored in memory or transmitted is done using encodings like UTF-8, UTF-16, and UTF-32:\n",
        "\n",
        "##UTF-8:\n",
        "\n",
        "The most common encoding on the web, it uses 1 to 4 bytes to represent each character. It's backward-compatible with ASCII (which uses 1 byte per character).\n",
        "\n",
        "##UTF-16:\n",
        "\n",
        "Uses 2 or 4 bytes per character.\n",
        "\n",
        "##UTF-32:\n",
        "\n",
        "Uses 4 bytes per character, offering a fixed-length encoding but requiring more memory.\n",
        "\n",
        "-----------\n",
        "##Compatibility:\n",
        "\n",
        "Unicode ensures that texts can be transferred between different platforms or systems without misinterpretation of the characters.\n",
        "\n",
        "Before Unicode, different systems used different encodings (e.g., ASCII, ISO-8859), which caused compatibility issues when dealing with characters outside the supported range (e.g., accented letters or non-Latin scripts).\n",
        "\n",
        "------------------------\n",
        "##Why Unicode is Important:\n",
        "###Multilingual Text:\n",
        "\n",
        "Unicode allows a document to include characters from different languages in the same text file.\n",
        "\n",
        "For example, you can mix English, Chinese, and Arabic characters seamlessly.\n",
        "\n",
        "###Emojis:\n",
        "\n",
        "Modern communication uses emojis extensively, and Unicode is responsible for encoding these emojis across devices and platforms.\n",
        "\n",
        "Consistency Across Systems: It ensures that the same character is represented consistently across different platforms and applications, eliminating the problems caused by incompatible character encodings in the past.\n",
        "\n",
        "--------------------\n",
        "###Example:\n",
        "In Python 3, strings are by default Unicode:\n",
        "\n",
        "    s = \"Hello, 世界\"  # The text \"Hello, World\" in English and Chinese\n",
        "Here, the string contains both Latin and Chinese characters, but Python will handle it as a Unicode string, allowing for seamless encoding and processing.\n",
        "\n",
        "If you want to represent characters using Unicode code points, you can use escape sequences like:\n",
        "            \n",
        "    s = \"\\u0041\"  # Represents the letter \"A\" (U+0041)"
      ],
      "metadata": {
        "id": "GIvkv8oOjOxU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZTgz1MbghMt"
      },
      "source": [
        "## View token tags\n",
        "Recall that you can obtain a particular token by its index position.\n",
        "* To view the coarse POS tag use `token.pos_`\n",
        "* To view the fine-grained tag use `token.tag_`\n",
        "* To view the description of either type of tag use `spacy.explain(tag)`\n",
        "\n",
        "<div class=\"alert alert-success\">Note that `token.pos` and `token.tag` return integer hash values; by adding the underscores we get the text equivalent that lives in **doc.vocab**.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLWoJKP0ghMt",
        "outputId": "d346b420-9cd7-4401-df9c-e214f29d5b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown fox jumped over the lazy dog's back.\n"
          ]
        }
      ],
      "source": [
        "# Print the full text:\n",
        "print(doc.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rXbNuX2ghMv",
        "outputId": "0b99f8f8-bf68-4aee-fdc4-37be38f68f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumped VERB VBD verb, past tense\n"
          ]
        }
      ],
      "source": [
        "# Print the fifth word and associated tags:\n",
        "print(doc[4].text, doc[4].pos_, doc[4].tag_, spacy.explain(doc[4].tag_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "You're accessing the 5th token (doc[4]) in the Doc object and printing out several properties related to this token, specifically its text, part-of-speech (POS) tag, detailed tag, and a human-readable explanation of the tag.\n",
        "\n",
        "-------------------------\n",
        "Here's a breakdown of what each component does:\n",
        "\n",
        "##doc[4].text:\n",
        "\n",
        "This returns the text of the 5th token in the sentence, which, based on the sentence \"The quick brown fox jumped over the lazy dog's back.\", is the word \"jumped\".\n",
        "\n",
        "##doc[4].pos_:\n",
        "\n",
        "This returns the coarse-grained part-of-speech tag (e.g., VERB, NOUN, ADJ).\n",
        "\n",
        "For \"jumped\", it will return VERB, since \"jumped\" is a verb.\n",
        "\n",
        "##doc[4].tag_:\n",
        "\n",
        "This returns the detailed part-of-speech tag based on the specific language model.\n",
        "\n",
        "In English, this is usually following the Penn Treebank tag set. For \"jumped\", it might return VBD (Verb, Past Tense).\n",
        "\n",
        "##spacy.explain(doc[4].tag_):\n",
        "\n",
        "This function provides a human-readable explanation for the specific tag. For the tag VBD, the explanation will be \"verb, past tense\".\n",
        "\n",
        "---------------------\n",
        "#Sample Output:\n",
        "For the 5th token \"jumped\":\n",
        "\n",
        "    jumped VERB VBD verb, past tense\n",
        "So, this line of code provides detailed information about the token, including its POS tag and an explanation of what that tag represents."
      ],
      "metadata": {
        "id": "5UzeXvYHmxMT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_9zd3a9ghMv"
      },
      "source": [
        "We can apply this technique to the entire Doc object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vunRB9xRghMv",
        "outputId": "dc6f8338-5fbc-480d-c08a-553b7b9eb433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The        DET      DT     determiner\n",
            "quick      ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
            "brown      ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
            "fox        NOUN     NN     noun, singular or mass\n",
            "jumped     VERB     VBD    verb, past tense\n",
            "over       ADP      IN     conjunction, subordinating or preposition\n",
            "the        DET      DT     determiner\n",
            "lazy       ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
            "dog        NOUN     NN     noun, singular or mass\n",
            "'s         PART     POS    possessive ending\n",
            "back       NOUN     NN     noun, singular or mass\n",
            ".          PUNCT    .      punctuation mark, sentence closer\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print the Tokens of a text\n",
        "## token.text:\n",
        "This prints the text of the token (the actual word or punctuation).\n",
        "\n",
        "## token.pos_:\n",
        "This prints the part-of-speech (POS) tag of the token, which is the broad category of the word (e.g., VERB, NOUN, ADJ).\n",
        "\n",
        "## token.tag_:\n",
        "This prints the fine-grained part-of-speech tag, which is a more specific tag (e.g., VBD for past-tense verb, NN for singular noun).\n",
        "\n",
        "##spacy.explain(token.tag_):\n",
        "This prints a human-readable explanation of the fine-grained part-of-speech tag.\n",
        "\n",
        "##F-strings with formatting:\n",
        "The {10}, {8}, and {6} inside the f-string control the width of the columns to make the output nicely aligned:\n",
        "\n",
        "{10} ensures the token.text field has a width of 10 characters.\n",
        "\n",
        "{8} makes sure the POS tag has a width of 8 characters.\n",
        "\n",
        "{6} ensures the fine-grained POS tag has a width of 6 characters.\n",
        "\n",
        "This formatting makes the output cleaner and easier to read.\n",
        "\n",
        "------------------\n",
        "#Example Output:\n",
        "For the sentence \"The quick brown fox jumped over the lazy dog's back.\", the output might look like this:\n",
        "\n",
        "    The        DET      DT     determiner\n",
        "    quick      ADJ      JJ     adjective\n",
        "    brown      ADJ      JJ     adjective\n",
        "    fox        NOUN     NN     noun, singular or mass\n",
        "    jumped     VERB     VBD    verb, past tense\n",
        "    over       ADP      IN     conjunction, subordinating or preposition\n",
        "    the        DET      DT     determiner\n",
        "    lazy       ADJ      JJ     adjective\n",
        "    dog        NOUN     NN     noun, singular or mass\n",
        "    's         PART     POS    possessive ending\n",
        "    back       NOUN     NN     noun, singular or mass\n",
        "    .          PUNCT    .      punctuation mark, sentence closer\n",
        "\n",
        "This output gives a nice table-like structure where:\n",
        "\n",
        "    The first column is the word (token),\n",
        "    The second column is the coarse POS tag,\n",
        "    The third column is the fine-grained POS tag,\n",
        "    The fourth column is the explanation of the fine-grained tag."
      ],
      "metadata": {
        "id": "goopY_rKn9gG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "azzUGpoAghMw"
      },
      "source": [
        "## Coarse-grained Part-of-speech Tags\n",
        "Every token is assigned a POS Tag from the following list:\n",
        "\n",
        "\n",
        "<table><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n",
        "    \n",
        "<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n",
        "<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n",
        "<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n",
        "<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n",
        "<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n",
        "<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n",
        "<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n",
        "<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n",
        "<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n",
        "<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n",
        "<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n",
        "<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n",
        "<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n",
        "<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n",
        "<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n",
        "<tr><td>SYM</td><td>symbol</td><td>*$, %, §, ©, +, −, ×, ÷, =, :), 😝*</td></tr>\n",
        "<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n",
        "<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n",
        "<tr><td>SPACE</td><td>space</td></tr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTRJTn8EghMw"
      },
      "source": [
        "___\n",
        "## Fine-grained Part-of-speech Tags\n",
        "Tokens are subsequently given a fine-grained tag as determined by morphology:\n",
        "<table>\n",
        "<tr><th>POS</th><th>Description</th><th>Fine-grained Tag</th><th>Description</th><th>Morphology</th></tr>\n",
        "<tr><td>ADJ</td><td>adjective</td><td>AFX</td><td>affix</td><td>Hyph=yes</td></tr>\n",
        "<tr><td>ADJ</td><td></td><td>JJ</td><td>adjective</td><td>Degree=pos</td></tr>\n",
        "<tr><td>ADJ</td><td></td><td>JJR</td><td>adjective, comparative</td><td>Degree=comp</td></tr>\n",
        "<tr><td>ADJ</td><td></td><td>JJS</td><td>adjective, superlative</td><td>Degree=sup</td></tr>\n",
        "<tr><td>ADJ</td><td></td><td>PDT</td><td>predeterminer</td><td>AdjType=pdt PronType=prn</td></tr>\n",
        "<tr><td>ADJ</td><td></td><td>PRP\\$</td><td>pronoun, possessive</td><td>PronType=prs Poss=yes</td></tr>\n",
        "<tr><td>ADJ</td><td></td><td>WDT</td><td>wh-determiner</td><td>PronType=int rel</td></tr>\n",
        "<tr><td>ADJ</td><td></td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>Poss=yes PronType=int rel</td></tr>\n",
        "<tr><td>ADP</td><td>adposition</td><td>IN</td><td>conjunction, subordinating or preposition</td><td></td></tr>\n",
        "<tr><td>ADV</td><td>adverb</td><td>EX</td><td>existential there</td><td>AdvType=ex</td></tr>\n",
        "<tr><td>ADV</td><td></td><td>RB</td><td>adverb</td><td>Degree=pos</td></tr>\n",
        "<tr><td>ADV</td><td></td><td>RBR</td><td>adverb, comparative</td><td>Degree=comp</td></tr>\n",
        "<tr><td>ADV</td><td></td><td>RBS</td><td>adverb, superlative</td><td>Degree=sup</td></tr>\n",
        "<tr><td>ADV</td><td></td><td>WRB</td><td>wh-adverb</td><td>PronType=int rel</td></tr>\n",
        "<tr><td>CONJ</td><td>conjunction</td><td>CC</td><td>conjunction, coordinating</td><td>ConjType=coor</td></tr>\n",
        "<tr><td>DET</td><td>determiner</td><td>DT</td><td>determiner</td><td></td></tr>\n",
        "<tr><td>INTJ</td><td>interjection</td><td>UH</td><td>interjection</td><td></td></tr>\n",
        "<tr><td>NOUN</td><td>noun</td><td>NN</td><td>noun, singular or mass</td><td>Number=sing</td></tr>\n",
        "<tr><td>NOUN</td><td></td><td>NNS</td><td>noun, plural</td><td>Number=plur</td></tr>\n",
        "<tr><td>NOUN</td><td></td><td>WP</td><td>wh-pronoun, personal</td><td>PronType=int rel</td></tr>\n",
        "<tr><td>NUM</td><td>numeral</td><td>CD</td><td>cardinal number</td><td>NumType=card</td></tr>\n",
        "<tr><td>PART</td><td>particle</td><td>POS</td><td>possessive ending</td><td>Poss=yes</td></tr>\n",
        "<tr><td>PART</td><td></td><td>RP</td><td>adverb, particle</td><td></td></tr>\n",
        "<tr><td>PART</td><td></td><td>TO</td><td>infinitival to</td><td>PartType=inf VerbForm=inf</td></tr>\n",
        "<tr><td>PRON</td><td>pronoun</td><td>PRP</td><td>pronoun, personal</td><td>PronType=prs</td></tr>\n",
        "<tr><td>PROPN</td><td>proper noun</td><td>NNP</td><td>noun, proper singular</td><td>NounType=prop Number=sign</td></tr>\n",
        "<tr><td>PROPN</td><td></td><td>NNPS</td><td>noun, proper plural</td><td>NounType=prop Number=plur</td></tr>\n",
        "<tr><td>PUNCT</td><td>punctuation</td><td>-LRB-</td><td>left round bracket</td><td>PunctType=brck PunctSide=ini</td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>-RRB-</td><td>right round bracket</td><td>PunctType=brck PunctSide=fin</td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>,</td><td>punctuation mark, comma</td><td>PunctType=comm</td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>:</td><td>punctuation mark, colon or ellipsis</td><td></td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>.</td><td>punctuation mark, sentence closer</td><td>PunctType=peri</td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>''</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>\"\"</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>``</td><td>opening quotation mark</td><td>PunctType=quot PunctSide=ini</td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>HYPH</td><td>punctuation mark, hyphen</td><td>PunctType=dash</td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>LS</td><td>list item marker</td><td>NumType=ord</td></tr>\n",
        "<tr><td>PUNCT</td><td></td><td>NFP</td><td>superfluous punctuation</td><td></td></tr>\n",
        "<tr><td>SYM</td><td>symbol</td><td>#</td><td>symbol, number sign</td><td>SymType=numbersign</td></tr>\n",
        "<tr><td>SYM</td><td></td><td>\\$</td><td>symbol, currency</td><td>SymType=currency</td></tr>\n",
        "<tr><td>SYM</td><td></td><td>SYM</td><td>symbol</td><td></td></tr>\n",
        "<tr><td>VERB</td><td>verb</td><td>BES</td><td>auxiliary \"be\"</td><td></td></tr>\n",
        "<tr><td>VERB</td><td></td><td>HVS</td><td>forms of \"have\"</td><td></td></tr>\n",
        "<tr><td>VERB</td><td></td><td>MD</td><td>verb, modal auxiliary</td><td>VerbType=mod</td></tr>\n",
        "<tr><td>VERB</td><td></td><td>VB</td><td>verb, base form</td><td>VerbForm=inf</td></tr>\n",
        "<tr><td>VERB</td><td></td><td>VBD</td><td>verb, past tense</td><td>VerbForm=fin Tense=past</td></tr>\n",
        "<tr><td>VERB</td><td></td><td>VBG</td><td>verb, gerund or present participle</td><td>VerbForm=part Tense=pres Aspect=prog</td></tr>\n",
        "<tr><td>VERB</td><td></td><td>VBN</td><td>verb, past participle</td><td>VerbForm=part Tense=past Aspect=perf</td></tr>\n",
        "<tr><td>VERB</td><td></td><td>VBP</td><td>verb, non-3rd person singular present</td><td>VerbForm=fin Tense=pres</td></tr>\n",
        "<tr><td>VERB</td><td></td><td>VBZ</td><td>verb, 3rd person singular present</td><td>VerbForm=fin Tense=pres Number=sing Person=3</td></tr>\n",
        "<tr><td>X</td><td>other</td><td>ADD</td><td>email</td><td></td></tr>\n",
        "<tr><td>X</td><td></td><td>FW</td><td>foreign word</td><td>Foreign=yes</td></tr>\n",
        "<tr><td>X</td><td></td><td>GW</td><td>additional word in multi-word expression</td><td></td></tr>\n",
        "<tr><td>X</td><td></td><td>XX</td><td>unknown</td><td></td></tr>\n",
        "<tr><td>SPACE</td><td>space</td><td>_SP</td><td>space</td><td></td></tr>\n",
        "<tr><td></td><td></td><td>NIL</td><td>missing tag</td><td></td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZnXBjFAghMx"
      },
      "source": [
        "For a current list of tags for all languages visit https://spacy.io/api/annotation#pos-tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdHDaDXdghMx"
      },
      "source": [
        "## Working with POS Tags\n",
        "In the English language, the same string of characters can have different meanings, even within the same sentence. For this reason, morphology is important. **spaCy** uses machine learning algorithms to best predict the use of a token in a sentence. Is *\"I read books on NLP\"* present or past tense? Is *wind* a verb or a noun?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vbN1Iw3ghMx",
        "outputId": "489c37ef-5ab7-4f40-f17d-bfd1073b7091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read       VERB     VBP    verb, non-3rd person singular present\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(u'I read books on NLP.')\n",
        "r = doc[1]\n",
        "\n",
        "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7iYL1KNghMy",
        "outputId": "e8a3c1c8-d91a-4d76-f10c-e00b5846cb44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read       VERB     VBD    verb, past tense\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(u'I read a book on NLP.')\n",
        "r = doc[1]\n",
        "\n",
        "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GohX_3asghMy"
      },
      "source": [
        "In the first example, with no other cues to work from, spaCy assumed that ***read*** was present tense.<br>In the second example the present tense form would be ***I am reading a book***, so spaCy assigned the past tense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd39n4CRghMy"
      },
      "source": [
        "## Counting POS Tags\n",
        "The `Doc.count_by()` method accepts a specific token attribute as its argument, and returns a frequency count of the given attribute as a dictionary object. Keys in the dictionary are the integer values of the given attribute ID, and values are the frequency. Counts of zero are not included."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMaU5qNsghMz",
        "outputId": "fe6bc3f1-820f-434e-bc2f-a3dd5a4dbcc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{90: 2, 84: 3, 92: 3, 100: 1, 85: 1, 94: 1, 97: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back.\")\n",
        "\n",
        "# Count the frequencies of different coarse-grained POS tags:\n",
        "POS_counts = doc.count_by(spacy.attrs.POS)\n",
        "POS_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counting the different types of part-of-speech\n",
        "    doc.count_by(spacy.attrs.POS):\n",
        "\n",
        "This counts how many times each part-of-speech (POS) tag appears in the doc.\n",
        "\n",
        "spacy.attrs.POS refers to the coarse-grained POS tags (like VERB, NOUN, ADJ).\n",
        "\n",
        "The count_by() method returns a dictionary where:\n",
        "The keys are the internal integer codes that represent different POS tags.\n",
        "\n",
        "The values are the counts of how many tokens in the document have that specific POS tag.\n",
        "\n",
        "----------------\n",
        "#The Output:\n",
        "\n",
        "    {90: 2, 84: 3, 92: 3, 100: 1, 85: 1, 94: 1, 97: 1}\n",
        "This dictionary shows the counts of different POS tags, where:\n",
        "\n",
        "    90 appeared 2 times,\n",
        "    84 appeared 3 times,\n",
        "    92 appeared 3 times, and so on.\n",
        "\n",
        "-----------------\n",
        "#Understanding the POS Tags:\n",
        "The numbers 90, 84, 92, etc., correspond to spaCy's internal representations of POS tags.\n",
        "\n",
        "To understand which POS tags these represent, we need to map these numbers back to the actual tag names.\n",
        "\n",
        "We can do this using spacy.explain() or by accessing spacy.attrs.POS mappings:\n",
        "\n",
        "--------------------\n",
        "#Example to Decode POS Tags:\n",
        "You can map the integer codes back to their POS names using this snippet:\n",
        "\n",
        "    for k, v in POS_counts.items():\n",
        "       print(f\"POS code: {k}, Count: {v}, POS: {doc.vocab[k].text}\")\n",
        "\n",
        "\n",
        "##Example Output:\n",
        "Let’s decode the numbers:\n",
        "\n",
        "    90: DET (determiner) – appears 2 times.\n",
        "    84: ADJ (adjective) – appears 3 times.\n",
        "    92: NOUN (noun) – appears 3 times.\n",
        "    100: VERB (verb) – appears 1 time.\n",
        "    85: ADP (adposition, like prepositions) – appears 1 time.\n",
        "    94: PART (particle) – appears 1 time.\n",
        "    97: PUNCT (punctuation) – appears 1 time.\n",
        "\n",
        "-------   \n",
        "##Meaning of Output:\n",
        "Now you can see what each of these numbers represents:\n",
        "\n",
        "\n",
        "{90: 2, 84: 3, 92: 3, 100: 1, 85: 1, 94: 1, 97: 1}\n",
        "Translates to:\n",
        "\n",
        "    DET (determiners): 2\n",
        "    ADJ (adjectives): 3\n",
        "    NOUN (nouns): 3\n",
        "    VERB (verbs): 1\n",
        "    ADP (adpositions): 1\n",
        "    PART (particles): 1\n",
        "    PUNCT (punctuation): 1\n",
        "\n",
        "This means that the sentence contains:\n",
        "\n",
        "    2 determiners (like \"the\"),\n",
        "    3 adjectives (like \"quick\", \"brown\", \"lazy\"),\n",
        "    3 nouns (like \"fox\", \"dog\", \"back\"),\n",
        "    1 verb (\"jumped\"),\n",
        "    1 adposition (like \"over\"),\n",
        "    1 particle (like \"'s\"),\n",
        "    1 punctuation mark (\".\")"
      ],
      "metadata": {
        "id": "FvGn0u9NrJjc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y_FqxFBghMz"
      },
      "source": [
        "This isn't very helpful until you decode the attribute ID:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1soe8xK-ghMz",
        "outputId": "359e895d-b9ae-411d-a8a0-a23a02adcaaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LANG'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "doc.vocab[83].text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn3Lj-2_ghMz"
      },
      "source": [
        "### Create a frequency list of POS tags from the entire document\n",
        "Since `POS_counts` returns a dictionary, we can obtain a list of keys with `POS_counts.items()`.<br>By sorting the list we have access to the tag and its count, in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CunLvEgwghMz",
        "outputId": "f447f368-6c3c-45e5-b19f-69f4a2a7df1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84. ADJ  : 3\n",
            "85. ADP  : 1\n",
            "90. DET  : 2\n",
            "92. NOUN : 3\n",
            "94. PART : 1\n",
            "97. PUNCT: 1\n",
            "100. VERB : 1\n"
          ]
        }
      ],
      "source": [
        "for k,v in sorted(POS_counts.items()):\n",
        "    print(f'{k}. {doc.vocab[k].text:{5}}: {v}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5bUMrf2ghM0",
        "outputId": "c1f75970-7e6c-4145-b2ca-4030c27b1866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74. POS : 1\n",
            "1292078113972184607. IN  : 1\n",
            "10554686591937588953. JJ  : 3\n",
            "12646065887601541794. .   : 1\n",
            "15267657372422890137. DT  : 2\n",
            "15308085513773655218. NN  : 3\n",
            "17109001835818727656. VBD : 1\n"
          ]
        }
      ],
      "source": [
        "# Count the different fine-grained tags:\n",
        "TAG_counts = doc.count_by(spacy.attrs.TAG)\n",
        "\n",
        "for k,v in sorted(TAG_counts.items()):\n",
        "    print(f'{k}. {doc.vocab[k].text:{4}}: {v}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl0yHigVghM0"
      },
      "source": [
        "<div class=\"alert alert-success\">**Why did the ID numbers get so big?** In spaCy, certain text values are hardcoded into `Doc.vocab` and take up the first several hundred ID numbers. Strings like 'NOUN' and 'VERB' are used frequently by internal operations. Others, like fine-grained tags, are assigned hash values as needed.</div>\n",
        "<div class=\"alert alert-success\">**Why don't SPACE tags appear?** In spaCy, only strings of spaces (two or more) are assigned tokens. Single spaces are not.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tezdvrahghM0",
        "outputId": "210514b2-8b09-4716-fd6f-d1edf0536c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400. advmod: 1\n",
            "402. amod: 3\n",
            "415. det : 2\n",
            "429. nsubj: 1\n",
            "439. pobj: 1\n",
            "443. prep: 1\n",
            "445. punct: 1\n",
            "8110129090154140942. case: 1\n",
            "8206900633647566924. ROOT: 1\n"
          ]
        }
      ],
      "source": [
        "# Count the different dependencies:\n",
        "DEP_counts = doc.count_by(spacy.attrs.DEP)\n",
        "\n",
        "for k,v in sorted(DEP_counts.items()):\n",
        "    print(f'{k}. {doc.vocab[k].text:{4}}: {v}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5n-DCHVghM0"
      },
      "source": [
        "Here we've shown `spacy.attrs.POS`, `spacy.attrs.TAG` and `spacy.attrs.DEP`.<br>Refer back to the **Vocabulary and Matching** lecture from the previous section for a table of **Other token attributes**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3xwkhJ2ghM0"
      },
      "source": [
        "___\n",
        "## Fine-grained POS Tag Examples\n",
        "These are some grammatical examples (shown in **bold**) of specific fine-grained tags. We've removed punctuation and rarely used tags:\n",
        "<table>\n",
        "<tr><th>POS</th><th>TAG</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
        "<tr><td>ADJ</td><td>AFX</td><td>affix</td><td>The Flintstones were a **pre**-historic family.</td></tr>\n",
        "<tr><td>ADJ</td><td>JJ</td><td>adjective</td><td>This is a **good** sentence.</td></tr>\n",
        "<tr><td>ADJ</td><td>JJR</td><td>adjective, comparative</td><td>This is a **better** sentence.</td></tr>\n",
        "<tr><td>ADJ</td><td>JJS</td><td>adjective, superlative</td><td>This is the **best** sentence.</td></tr>\n",
        "<tr><td>ADJ</td><td>PDT</td><td>predeterminer</td><td>Waking up is **half** the battle.</td></tr>\n",
        "<tr><td>ADJ</td><td>PRP\\$</td><td>pronoun, possessive</td><td>**His** arm hurts.</td></tr>\n",
        "<tr><td>ADJ</td><td>WDT</td><td>wh-determiner</td><td>It's blue, **which** is odd.</td></tr>\n",
        "<tr><td>ADJ</td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>We don't know **whose** it is.</td></tr>\n",
        "<tr><td>ADP</td><td>IN</td><td>conjunction, subordinating or preposition</td><td>It arrived **in** a box.</td></tr>\n",
        "<tr><td>ADV</td><td>EX</td><td>existential there</td><td>**There** is cake.</td></tr>\n",
        "<tr><td>ADV</td><td>RB</td><td>adverb</td><td>He ran **quickly**.</td></tr>\n",
        "<tr><td>ADV</td><td>RBR</td><td>adverb, comparative</td><td>He ran **quicker**.</td></tr>\n",
        "<tr><td>ADV</td><td>RBS</td><td>adverb, superlative</td><td>He ran **fastest**.</td></tr>\n",
        "<tr><td>ADV</td><td>WRB</td><td>wh-adverb</td><td>**When** was that?</td></tr>\n",
        "<tr><td>CONJ</td><td>CC</td><td>conjunction, coordinating</td><td>The balloon popped **and** everyone jumped.</td></tr>\n",
        "<tr><td>DET</td><td>DT</td><td>determiner</td><td>**This** is **a** sentence.</td></tr>\n",
        "<tr><td>INTJ</td><td>UH</td><td>interjection</td><td>**Um**, I don't know.</td></tr>\n",
        "<tr><td>NOUN</td><td>NN</td><td>noun, singular or mass</td><td>This is a **sentence**.</td></tr>\n",
        "<tr><td>NOUN</td><td>NNS</td><td>noun, plural</td><td>These are **words**.</td></tr>\n",
        "<tr><td>NOUN</td><td>WP</td><td>wh-pronoun, personal</td><td>**Who** was that?</td></tr>\n",
        "<tr><td>NUM</td><td>CD</td><td>cardinal number</td><td>I want **three** things.</td></tr>\n",
        "<tr><td>PART</td><td>POS</td><td>possessive ending</td><td>Fred**'s** name is short.</td></tr>\n",
        "<tr><td>PART</td><td>RP</td><td>adverb, particle</td><td>Put it **back**!</td></tr>\n",
        "<tr><td>PART</td><td>TO</td><td>infinitival to</td><td>I want **to** go.</td></tr>\n",
        "<tr><td>PRON</td><td>PRP</td><td>pronoun, personal</td><td>**I** want **you** to go.</td></tr>\n",
        "<tr><td>PROPN</td><td>NNP</td><td>noun, proper singular</td><td>**Kilroy** was here.</td></tr>\n",
        "<tr><td>PROPN</td><td>NNPS</td><td>noun, proper plural</td><td>The **Flintstones** were a pre-historic family.</td></tr>\n",
        "<tr><td>VERB</td><td>MD</td><td>verb, modal auxiliary</td><td>This **could** work.</td></tr>\n",
        "<tr><td>VERB</td><td>VB</td><td>verb, base form</td><td>I want to **go**.</td></tr>\n",
        "<tr><td>VERB</td><td>VBD</td><td>verb, past tense</td><td>This **was** a sentence.</td></tr>\n",
        "<tr><td>VERB</td><td>VBG</td><td>verb, gerund or present participle</td><td>I am **going**.</td></tr>\n",
        "<tr><td>VERB</td><td>VBN</td><td>verb, past participle</td><td>The treasure was **lost**.</td></tr>\n",
        "<tr><td>VERB</td><td>VBP</td><td>verb, non-3rd person singular present</td><td>I **want** to go.</td></tr>\n",
        "<tr><td>VERB</td><td>VBZ</td><td>verb, 3rd person singular present</td><td>He **wants** to go.</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa3ISH3EghM1"
      },
      "source": [
        "### Up Next: Visualizing POS"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}